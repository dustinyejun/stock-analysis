"""
è‚¡ç¥¨é€‰æ‹©å™¨æ¨¡å— - é›†æˆæ•°æ®è·å–ã€æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å’Œé€‰è‚¡è§„åˆ™
"""
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ä¸´æ—¶å¯¼å…¥å¤„ç†
try:
    from src.data_fetcher import StockDataFetcher
    from src.indicators import TechnicalIndicators
    from src.selection_rules import RuleEngine, RuleRegistry, SelectionResult, RuleResult
    from src.rules import GoldenPitRule, TrendBreakoutRule
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œåˆ›å»ºå ä½ç¬¦
    print("è­¦å‘Š: æŸäº›æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨æµ‹è¯•æ¨¡å¼")
    StockDataFetcher = None
    TechnicalIndicators = None


import time

class StockSelector:
    """
    è‚¡ç¥¨é€‰æ‹©å™¨ä¸»ç±»
    
    é›†æˆæ•°æ®è·å–ã€æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å’Œé€‰è‚¡è§„åˆ™å¼•æ“ï¼Œæä¾›å®Œæ•´çš„é€‰è‚¡åŠŸèƒ½
    """
    
    def __init__(self, data_fetcher=None, indicators_calculator=None, rule_engine=None):
        """
        åˆå§‹åŒ–è‚¡ç¥¨é€‰æ‹©å™¨
        
        Args:
            data_fetcher: æ•°æ®è·å–å™¨å®ä¾‹
            indicators_calculator: æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å™¨å®ä¾‹
            rule_engine: é€‰è‚¡è§„åˆ™å¼•æ“å®ä¾‹
        """
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.data_fetcher = data_fetcher or (StockDataFetcher() if StockDataFetcher else None)
        self.indicators_calculator = indicators_calculator or (TechnicalIndicators() if TechnicalIndicators else None)
        
        # åˆå§‹åŒ–è§„åˆ™å¼•æ“å’Œæ³¨å†Œé»˜è®¤è§„åˆ™
        if rule_engine is None:
            registry = RuleRegistry()
            self.rule_engine = RuleEngine(registry)
            self._register_default_rules()
        else:
            self.rule_engine = rule_engine
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_processed': 0,
            'successful_scans': 0,
            'failed_scans': 0,
            'rules_applied': 0,
            'results_generated': 0
        }
    
    def _register_default_rules(self):
        """æ³¨å†Œé»˜è®¤çš„é€‰è‚¡è§„åˆ™"""
        try:
            # æ³¨å†Œé»„é‡‘å‘è§„åˆ™
            golden_pit = GoldenPitRule()
            self.rule_engine.add_rule(golden_pit)
            
            # æ³¨å†Œè¶‹åŠ¿çªç ´è§„åˆ™
            trend_breakout = TrendBreakoutRule()
            self.rule_engine.add_rule(trend_breakout)
            
            self.logger.info("æˆåŠŸæ³¨å†Œé»˜è®¤é€‰è‚¡è§„åˆ™")
        except Exception as e:
            self.logger.error(f"æ³¨å†Œé»˜è®¤è§„åˆ™å¤±è´¥: {str(e)}")
    
    def add_rule(self, rule):
        """
        æ·»åŠ è‡ªå®šä¹‰é€‰è‚¡è§„åˆ™
        
        Args:
            rule: é€‰è‚¡è§„åˆ™å®ä¾‹
        """
        self.rule_engine.add_rule(rule)
    
    def scan_single_stock(self, symbol: str, period: int = 120, 
                         rule_names: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        æ‰«æå•åªè‚¡ç¥¨
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            period: æ•°æ®å‘¨æœŸï¼ˆå¤©æ•°ï¼‰
            rule_names: è¦åº”ç”¨çš„è§„åˆ™åç§°åˆ—è¡¨
            
        Returns:
            æ‰«æç»“æœå­—å…¸
        """
        try:
            self.stats['total_processed'] += 1
            
            # è·å–è‚¡ç¥¨æ•°æ®
            if not self.data_fetcher:
                return {
                    'symbol': symbol,
                    'success': False,
                    'error': 'data_fetcher_not_available',
                    'results': [],
                    'composite_score': 0.0
                }
            
            stock_data = self.data_fetcher.get_stock_data(symbol, period=period)
            if stock_data is None or stock_data.empty:
                return {
                    'symbol': symbol,
                    'success': False,
                    'error': 'no_data_available',
                    'results': [],
                    'composite_score': 0.0
                }
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            if not self.indicators_calculator:
                return {
                    'symbol': symbol,
                    'success': False,
                    'error': 'indicators_calculator_not_available',
                    'results': [],
                    'composite_score': 0.0
                }
            
            indicators_data = self.indicators_calculator.get_comprehensive_indicators(stock_data)
            
            # åº”ç”¨é€‰è‚¡è§„åˆ™
            results = self.rule_engine.apply_rules(symbol, stock_data, indicators_data, rule_names)
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            composite_score, score_details = self.rule_engine.calculate_composite_score(results)
            
            self.stats['successful_scans'] += 1
            self.stats['rules_applied'] += len(results)
            self.stats['results_generated'] += len([r for r in results if r.result != RuleResult.ERROR])
            
            return {
                'symbol': symbol,
                'success': True,
                'results': results,
                'composite_score': composite_score,
                'score_details': score_details,
                'data_info': {
                    'data_length': len(stock_data),
                    'date_range': f"{stock_data.index[0].strftime('%Y-%m-%d')} to {stock_data.index[-1].strftime('%Y-%m-%d')}",
                    'indicators_count': len(indicators_data.columns)
                }
            }
            
        except Exception as e:
            self.stats['failed_scans'] += 1
            self.logger.error(f"æ‰«æè‚¡ç¥¨ {symbol} å¤±è´¥: {str(e)}")
            return {
                'symbol': symbol,
                'success': False,
                'error': str(e),
                'results': [],
                'composite_score': 0.0
            }
    
    def scan_stocks(self, symbols: List[str], period: int = 120, 
                   rule_names: Optional[List[str]] = None,
                   max_workers: int = 5,
                   min_score: float = 60.0,
                   progress_callback: Optional[callable] = None) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æ‰«æè‚¡ç¥¨
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            period: æ•°æ®å‘¨æœŸï¼ˆå¤©æ•°ï¼‰
            rule_names: è¦åº”ç”¨çš„è§„åˆ™åç§°åˆ—è¡¨
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
            min_score: æœ€ä½åˆ†æ•°é˜ˆå€¼
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            æ‰«æç»“æœåˆ—è¡¨ï¼ŒæŒ‰ç»¼åˆè¯„åˆ†é™åºæ’åˆ—
        """
        results = []
        processed_count = 0
        total_count = len(symbols)
        
        self.logger.info(f"å¼€å§‹æ‰¹é‡æ‰«æ {total_count} åªè‚¡ç¥¨ï¼Œä½¿ç”¨ {max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
        start_time = time.time()
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_symbol = {
                executor.submit(self.scan_single_stock, symbol, period, rule_names): symbol
                for symbol in symbols
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                processed_count += 1
                
                try:
                    result = future.result()
                    if result['success'] and result['composite_score'] >= min_score:
                        results.append(result)
                        self.logger.debug(f"è‚¡ç¥¨ {symbol} é€šè¿‡ç­›é€‰ï¼Œè¯„åˆ†: {result['composite_score']:.1f}")
                    elif result['success']:
                        self.logger.debug(f"è‚¡ç¥¨ {symbol} è¯„åˆ†ä¸è¶³ï¼Œè¯„åˆ†: {result['composite_score']:.1f}")
                    else:
                        self.logger.warning(f"è‚¡ç¥¨ {symbol} æ‰«æå¤±è´¥: {result.get('error', 'unknown_error')}")
                        
                except Exception as e:
                    self.logger.error(f"å¤„ç†è‚¡ç¥¨ {symbol} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                
                # è°ƒç”¨è¿›åº¦å›è°ƒ
                if progress_callback:
                    try:
                        progress_callback(processed_count, total_count, len(results))
                    except Exception as e:
                        self.logger.warning(f"è¿›åº¦å›è°ƒæ‰§è¡Œå¤±è´¥: {str(e)}")
                
                # å®šæœŸè¾“å‡ºè¿›åº¦
                if processed_count % 50 == 0 or processed_count == total_count:
                    elapsed_time = time.time() - start_time
                    avg_time = elapsed_time / processed_count
                    remaining_time = avg_time * (total_count - processed_count)
                    
                    self.logger.info(
                        f"è¿›åº¦: {processed_count}/{total_count} ({processed_count/total_count*100:.1f}%), "
                        f"ç¬¦åˆæ¡ä»¶: {len(results)}åª, "
                        f"å·²ç”¨æ—¶: {elapsed_time:.1f}s, "
                        f"é¢„è®¡å‰©ä½™: {remaining_time:.1f}s"
                    )
        
        # æŒ‰ç»¼åˆè¯„åˆ†é™åºæ’åˆ—
        results.sort(key=lambda x: x['composite_score'], reverse=True)
        
        total_time = time.time() - start_time
        self.logger.info(
            f"æ‰¹é‡æ‰«æå®Œæˆï¼æ€»ç”¨æ—¶: {total_time:.1f}s, "
            f"å¹³å‡æ¯åªè‚¡ç¥¨: {total_time/total_count:.2f}s, "
            f"æ‰¾åˆ° {len(results)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨"
        )
        
        return results

    def scan_stocks_advanced(self, symbols: List[str], period: int = 120,
                             rule_names: Optional[List[str]] = None,
                             max_workers: int = 5,
                             min_score: float = 60.0,
                             batch_size: int = 100,
                             save_results: bool = False,
                             result_file: str = None) -> Dict[str, Any]:
        """
        é«˜çº§æ‰¹é‡æ‰«æåŠŸèƒ½ï¼Œæ”¯æŒæ‰¹å¤„ç†ã€ç»“æœä¿å­˜ç­‰
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            period: æ•°æ®å‘¨æœŸï¼ˆå¤©æ•°ï¼‰
            rule_names: è¦åº”ç”¨çš„è§„åˆ™åç§°åˆ—è¡¨
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
            min_score: æœ€ä½åˆ†æ•°é˜ˆå€¼
            batch_size: æ‰¹å¤„ç†å¤§å°
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            result_file: ç»“æœæ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«æ‰«æç»“æœå’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        start_time = time.time()
        total_results = []
        batch_stats = []
        
        self.logger.info(f"å¼€å§‹é«˜çº§æ‰¹é‡æ‰«æ {len(symbols)} åªè‚¡ç¥¨ï¼Œæ‰¹å¤„ç†å¤§å°: {batch_size}")
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(symbols), batch_size):
            batch_symbols = symbols[i:i + batch_size]
            batch_start_time = time.time()
            
            self.logger.info(f"å¤„ç†ç¬¬ {i//batch_size + 1} æ‰¹ï¼Œè‚¡ç¥¨æ•°é‡: {len(batch_symbols)}")
            
            # æ‰¹é‡æ‰«æ
            batch_results = self.scan_stocks(
                batch_symbols, period, rule_names, max_workers, min_score,
                progress_callback=lambda processed, total, found: 
                    self.logger.debug(f"æ‰¹å†…è¿›åº¦: {processed}/{total}, æ‰¾åˆ°: {found}")
            )
            
            total_results.extend(batch_results)
            
            # è®°å½•æ‰¹æ¬¡ç»Ÿè®¡
            batch_time = time.time() - batch_start_time
            batch_stats.append({
                'batch_number': i//batch_size + 1,
                'symbols_count': len(batch_symbols),
                'results_count': len(batch_results),
                'processing_time': batch_time,
                'avg_time_per_stock': batch_time / len(batch_symbols)
            })
            
            self.logger.info(f"ç¬¬ {i//batch_size + 1} æ‰¹å®Œæˆï¼Œç”¨æ—¶: {batch_time:.1f}sï¼Œæ‰¾åˆ° {len(batch_results)} åªè‚¡ç¥¨")
        
        # æœ€ç»ˆæ’åº
        total_results.sort(key=lambda x: x['composite_score'], reverse=True)
        
        # ç”Ÿæˆç»¼åˆç»Ÿè®¡
        total_time = time.time() - start_time
        comprehensive_stats = {
            'total_symbols': len(symbols),
            'qualified_stocks': len(total_results),
            'qualification_rate': len(total_results) / len(symbols) * 100,
            'total_processing_time': total_time,
            'avg_time_per_stock': total_time / len(symbols),
            'batches_processed': len(batch_stats),
            'batch_stats': batch_stats
        }
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        if save_results:
            result_data = {
                'scan_time': start_time,
                'parameters': {
                    'period': period,
                    'rule_names': rule_names,
                    'min_score': min_score,
                    'batch_size': batch_size
                },
                'statistics': comprehensive_stats,
                'results': total_results
            }
            
            if not result_file:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                result_file = f"scan_results_{timestamp}.json"
            
            try:
                import json
                import os
                
                # ç¡®ä¿resultsç›®å½•å­˜åœ¨
                os.makedirs('results', exist_ok=True)
                result_path = os.path.join('results', result_file)
                
                with open(result_path, 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, ensure_ascii=False, indent=2, default=str)
                
                self.logger.info(f"æ‰«æç»“æœå·²ä¿å­˜åˆ°: {result_path}")
                comprehensive_stats['result_file'] = result_path
                
            except Exception as e:
                self.logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
        
        self.logger.info(
            f"é«˜çº§æ‰«æå®Œæˆï¼æ€»ç”¨æ—¶: {total_time:.1f}sï¼Œ"
            f"æ‰¾åˆ° {len(total_results)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œ"
            f"åˆæ ¼ç‡: {comprehensive_stats['qualification_rate']:.2f}%"
        )
        
        return {
            'results': total_results,
            'statistics': comprehensive_stats,
            'rule_descriptions': self.get_rule_descriptions(),
            'selector_statistics': self.get_statistics()
        }

    
    def format_results_summary(self, results: List[Dict[str, Any]], 
                               top_n: int = 20) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–æ‰«æç»“æœæ‘˜è¦
        
        Args:
            results: æ‰«æç»“æœåˆ—è¡¨
            top_n: æ˜¾ç¤ºå‰Nåªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
            
        Returns:
            æ ¼å¼åŒ–åçš„ç»“æœæ‘˜è¦
        """
        if not results:
            return {
                'summary': 'æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨',
                'total_count': 0,
                'top_stocks': [],
                'score_distribution': {},
                'rule_performance': {}
            }
        
        # åŸºæœ¬ç»Ÿè®¡
        total_count = len(results)
        scores = [r['composite_score'] for r in results]
        avg_score = sum(scores) / len(scores)
        
        # åˆ†æ•°åˆ†å¸ƒ
        score_ranges = {
            '90-100': len([s for s in scores if 90 <= s <= 100]),
            '80-89': len([s for s in scores if 80 <= s < 90]),
            '70-79': len([s for s in scores if 70 <= s < 80]),
            '60-69': len([s for s in scores if 60 <= s < 70])
        }
        
        # è§„åˆ™è¡¨ç°ç»Ÿè®¡
        rule_stats = {}
        for result in results:
            for rule_result in result.get('results', []):
                rule_name = rule_result.rule_name
                if rule_name not in rule_stats:
                    rule_stats[rule_name] = {'pass': 0, 'fail': 0, 'partial': 0}
                
                if rule_result.result.name == 'PASS':
                    rule_stats[rule_name]['pass'] += 1
                elif rule_result.result.name == 'FAIL':
                    rule_stats[rule_name]['fail'] += 1
                elif rule_result.result.name == 'PARTIAL':
                    rule_stats[rule_name]['partial'] += 1
        
        # å‰Nåªè‚¡ç¥¨è¯¦æƒ…
        top_stocks = []
        for i, result in enumerate(results[:top_n]):
            stock_info = {
                'rank': i + 1,
                'symbol': result['symbol'],
                'composite_score': result['composite_score'],
                'rule_results': []
            }
            
            # æ·»åŠ æ¯ä¸ªè§„åˆ™çš„ç»“æœ
            for rule_result in result.get('results', []):
                stock_info['rule_results'].append({
                    'rule_name': rule_result.rule_name,
                    'result': rule_result.result.name,
                    'score': rule_result.score,
                    'confidence': rule_result.confidence,
                    'reason': rule_result.reason[:100] + '...' if len(rule_result.reason) > 100 else rule_result.reason
                })
            
            top_stocks.append(stock_info)
        
        return {
            'summary': f'æ‰¾åˆ° {total_count} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨',
            'total_count': total_count,
            'average_score': round(avg_score, 2),
            'highest_score': max(scores),
            'lowest_score': min(scores),
            'score_distribution': score_ranges,
            'rule_performance': rule_stats,
            'top_stocks': top_stocks
        }
    
    def export_results_to_csv(self, results: List[Dict[str, Any]], 
                              filename: str = None) -> str:
        """
        å¯¼å‡ºç»“æœåˆ°CSVæ–‡ä»¶
        
        Args:
            results: æ‰«æç»“æœåˆ—è¡¨
            filename: è¾“å‡ºæ–‡ä»¶å
            
        Returns:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        import csv
        import os
        from datetime import datetime
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"stock_selection_results_{timestamp}.csv"
        
        # ç¡®ä¿resultsç›®å½•å­˜åœ¨
        os.makedirs('results', exist_ok=True)
        filepath = os.path.join('results', filename)
        
        try:
            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                # å®šä¹‰CSVåˆ—
                fieldnames = [
                    'rank', 'symbol', 'composite_score', 
                    'golden_pit_result', 'golden_pit_score', 'golden_pit_confidence',
                    'trend_breakout_result', 'trend_breakout_score', 'trend_breakout_confidence',
                    'data_length', 'date_range', 'indicators_count'
                ]
                
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for rank, result in enumerate(results, 1):
                    row_data = {
                        'rank': rank,
                        'symbol': result['symbol'],
                        'composite_score': round(result['composite_score'], 2)
                    }
                    
                    # æ·»åŠ æ•°æ®ä¿¡æ¯
                    data_info = result.get('data_info', {})
                    row_data.update({
                        'data_length': data_info.get('data_length', ''),
                        'date_range': data_info.get('date_range', ''),
                        'indicators_count': data_info.get('indicators_count', '')
                    })
                    
                    # æ·»åŠ è§„åˆ™ç»“æœ
                    for rule_result in result.get('results', []):
                        rule_name = rule_result.rule_name.lower().replace(' ', '_')
                        row_data.update({
                            f'{rule_name}_result': rule_result.result.name,
                            f'{rule_name}_score': round(rule_result.score, 2),
                            f'{rule_name}_confidence': round(rule_result.confidence, 2)
                        })
                    
                    writer.writerow(row_data)
            
            self.logger.info(f"ç»“æœå·²å¯¼å‡ºåˆ°CSVæ–‡ä»¶: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºCSVæ–‡ä»¶å¤±è´¥: {str(e)}")
            return None

    
    def save_scan_history(self, scan_results: Dict[str, Any], 
                          metadata: Dict[str, Any] = None) -> str:
        """
        ä¿å­˜æ‰«æå†å²è®°å½•
        
        Args:
            scan_results: æ‰«æç»“æœæ•°æ®
            metadata: é¢å¤–çš„å…ƒæ•°æ®ä¿¡æ¯
            
        Returns:
            å†å²è®°å½•æ–‡ä»¶è·¯å¾„
        """
        import json
        import os
        from datetime import datetime
        
        timestamp = datetime.now()
        history_data = {
            'scan_id': timestamp.strftime("%Y%m%d_%H%M%S"),
            'timestamp': timestamp.isoformat(),
            'metadata': metadata or {},
            'results_summary': {
                'total_stocks_scanned': scan_results.get('statistics', {}).get('total_symbols', 0),
                'qualified_stocks': len(scan_results.get('results', [])),
                'processing_time': scan_results.get('statistics', {}).get('total_processing_time', 0),
                'qualification_rate': scan_results.get('statistics', {}).get('qualification_rate', 0)
            },
            'parameters': scan_results.get('statistics', {}).get('parameters', {}),
            'top_10_results': scan_results.get('results', [])[:10]  # åªä¿å­˜å‰10ä¸ªç»“æœ
        }
        
        # ç¡®ä¿historyç›®å½•å­˜åœ¨
        os.makedirs('history', exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†å†å²è®°å½•
        history_file = f"scan_history_{history_data['scan_id']}.json"
        history_path = os.path.join('history', history_file)
        
        try:
            with open(history_path, 'w', encoding='utf-8') as f:
                json.dump(history_data, f, ensure_ascii=False, indent=2, default=str)
            
            # æ›´æ–°å†å²è®°å½•ç´¢å¼•
            self._update_history_index(history_data)
            
            self.logger.info(f"æ‰«æå†å²è®°å½•å·²ä¿å­˜: {history_path}")
            return history_path
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {str(e)}")
            return None
    
    def _update_history_index(self, history_data: Dict[str, Any]):
        """æ›´æ–°å†å²è®°å½•ç´¢å¼•"""
        import json
        import os
        
        index_path = os.path.join('history', 'scan_history_index.json')
        
        # è¯»å–ç°æœ‰ç´¢å¼•
        if os.path.exists(index_path):
            try:
                with open(index_path, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
            except:
                index_data = {'scans': []}
        else:
            index_data = {'scans': []}
        
        # æ·»åŠ æ–°è®°å½•
        index_entry = {
            'scan_id': history_data['scan_id'],
            'timestamp': history_data['timestamp'],
            'total_stocks': history_data['results_summary']['total_stocks_scanned'],
            'qualified_stocks': history_data['results_summary']['qualified_stocks'],
            'qualification_rate': history_data['results_summary']['qualification_rate'],
            'processing_time': history_data['results_summary']['processing_time']
        }
        
        index_data['scans'].insert(0, index_entry)  # æœ€æ–°çš„åœ¨å‰é¢
        
        # åªä¿ç•™æœ€è¿‘50æ¬¡æ‰«æè®°å½•
        if len(index_data['scans']) > 50:
            index_data['scans'] = index_data['scans'][:50]
        
        # ä¿å­˜æ›´æ–°åçš„ç´¢å¼•
        try:
            with open(index_path, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            self.logger.error(f"æ›´æ–°å†å²ç´¢å¼•å¤±è´¥: {str(e)}")
    
    def get_scan_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æ‰«æå†å²è®°å½•
        
        Args:
            limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶
            
        Returns:
            å†å²è®°å½•åˆ—è¡¨
        """
        import json
        import os
        
        index_path = os.path.join('history', 'scan_history_index.json')
        
        if not os.path.exists(index_path):
            return []
        
        try:
            with open(index_path, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            
            return index_data.get('scans', [])[:limit]
            
        except Exception as e:
            self.logger.error(f"è¯»å–å†å²è®°å½•å¤±è´¥: {str(e)}")
            return []
    
    def scan_all_stocks(self, period: int = 120, 
                       rule_names: Optional[List[str]] = None,
                       max_workers: int = 5,
                       min_score: float = 60.0,
                       limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        æ‰«ææ‰€æœ‰è‚¡ç¥¨
        
        Args:
            period: æ•°æ®å‘¨æœŸï¼ˆå¤©æ•°ï¼‰
            rule_names: è¦åº”ç”¨çš„è§„åˆ™åç§°åˆ—è¡¨
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
            min_score: æœ€ä½åˆ†æ•°é˜ˆå€¼
            limit: æœ€å¤§å¤„ç†è‚¡ç¥¨æ•°é‡é™åˆ¶
            
        Returns:
            æ‰«æç»“æœåˆ—è¡¨ï¼ŒæŒ‰ç»¼åˆè¯„åˆ†é™åºæ’åˆ—
        """
        if not self.data_fetcher:
            self.logger.error("æ•°æ®è·å–å™¨ä¸å¯ç”¨")
            return []
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = self.data_fetcher.get_stock_list()
        if not stock_list:
            self.logger.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return []
        
        # æå–è‚¡ç¥¨ä»£ç 
        symbols = [stock['code'] for stock in stock_list]
        
        # åº”ç”¨æ•°é‡é™åˆ¶
        if limit and limit < len(symbols):
            symbols = symbols[:limit]
            self.logger.info(f"åº”ç”¨æ•°é‡é™åˆ¶ï¼Œåªå¤„ç†å‰ {limit} åªè‚¡ç¥¨")
        
        return self.scan_stocks(symbols, period, rule_names, max_workers, min_score)
    
    def get_rule_descriptions(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰è§„åˆ™çš„æè¿°ä¿¡æ¯"""
        descriptions = []
        
        for rule_name in self.rule_engine.registry.list_rules():
            rule = self.rule_engine.registry.get_rule(rule_name)
            if rule and hasattr(rule, 'get_rule_description'):
                descriptions.append(rule.get_rule_description())
            else:
                descriptions.append({
                    'name': rule_name,
                    'description': 'è§„åˆ™æè¿°ä¸å¯ç”¨',
                    'conditions': [],
                    'parameters': {},
                    'thresholds': {}
                })
        
        return descriptions
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–é€‰æ‹©å™¨ç»Ÿè®¡ä¿¡æ¯"""
        engine_stats = self.rule_engine.get_statistics()
        
        return {
            'selector_stats': self.stats,
            'rule_engine_stats': engine_stats,
            'performance': {
                'success_rate': self.stats['successful_scans'] / self.stats['total_processed'] if self.stats['total_processed'] > 0 else 0,
                'avg_rules_per_scan': self.stats['rules_applied'] / self.stats['total_processed'] if self.stats['total_processed'] > 0 else 0,
            }
        }
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'total_processed': 0,
            'successful_scans': 0,
            'failed_scans': 0,
            'rules_applied': 0,
            'results_generated': 0
        }
        
        # é‡ç½®è§„åˆ™å¼•æ“ç»Ÿè®¡
        for rule_name in self.rule_engine.registry.list_rules():
            rule = self.rule_engine.registry.get_rule(rule_name)
            if rule:
                rule.reset_statistics()
        
        self.rule_engine.clear_history()
        self.logger.info("ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")


def create_test_stock_selector():
    """åˆ›å»ºç”¨äºæµ‹è¯•çš„è‚¡ç¥¨é€‰æ‹©å™¨å®ä¾‹"""
    return StockSelector()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª è‚¡ç¥¨é€‰æ‹©å™¨æµ‹è¯•")
    
    try:
        # åˆ›å»ºé€‰æ‹©å™¨
        selector = StockSelector()
        print("âœ… è‚¡ç¥¨é€‰æ‹©å™¨åˆ›å»ºæˆåŠŸ")
        
        # è·å–è§„åˆ™æè¿°
        rules = selector.get_rule_descriptions()
        print(f"âœ… è·å–è§„åˆ™æè¿°æˆåŠŸ: {len(rules)} æ¡è§„åˆ™")
        
        for rule in rules:
            print(f"  - {rule['name']}: {rule['description']}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = selector.get_statistics()
        print(f"âœ… ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ: {stats['rule_engine_stats']['registry']['total_rules']} æ¡è§„åˆ™")
        
        # æµ‹è¯•å•åªè‚¡ç¥¨æ‰«æï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰
        if selector.data_fetcher and selector.indicators_calculator:
            print("ğŸ”„ æµ‹è¯•å•åªè‚¡ç¥¨æ‰«æ...")
            result = selector.scan_single_stock("000001", period=60)
            if result['success']:
                print(f"âœ… å•åªè‚¡ç¥¨æ‰«ææˆåŠŸ: ç»¼åˆè¯„åˆ† {result['composite_score']:.1f}")
            else:
                print(f"âš ï¸ å•åªè‚¡ç¥¨æ‰«æå¤±è´¥: {result.get('error', 'unknown_error')}")
        else:
            print("âš ï¸ æ•°æ®è·å–æˆ–æŒ‡æ ‡è®¡ç®—æ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡æ‰«ææµ‹è¯•")
        
        print("ğŸ‰ è‚¡ç¥¨é€‰æ‹©å™¨åŸºç¡€æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()